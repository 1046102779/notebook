**学习永不止步**

#### 一致性hash

我是两次遇到hash一致性相关问题：
1. 需要设计电单车的智能锁平台，如果线上有百万个锁接入锁平台，考虑到高可用，一个tcp服务存在单点问题；则需要设计支持百万量级的实时在线管理平台，所以需要在接入层考虑如何把锁全部均衡的接入到各个锁服务平台，同时如果一个服务挂掉，则怎样使锁离线重连抖动最小，则考虑了在nginx层引入hash一致性；
2. Amazon的Dynamo去中心化的高键值存储系统，依赖hash一致性算法。

我看了第一篇，写得很不错

[一致性hash算法](https://blog.csdn.net/sparkliang/article/details/5279393)

[白话解析：一致性hash算法](http://www.zsythink.net/archives/1182)

```shell
总结：
1.通过环的引入和hash计算节点值和目标值的映射，解决雪崩问题；
2.引入中间层虚拟节点列表，使得节点上存储的数据尽量平衡
```

## [互联网技术架构](https://github.com/davideuler/architecture.of.internet-product)

### 微博架构

看了微博架构的全部文章，[微博数据库那些事儿:3个变迁阶段背后的设计思想](https://github.com/davideuler/architecture.of.internet-product/blob/master/2.%E5%BE%AE%E5%8D%9A%E6%9E%B6%E6%9E%84/%E5%BE%AE%E5%8D%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%EF%BC%9A3%E4%B8%AA%E5%8F%98%E8%BF%81%E9%98%B6%E6%AE%B5%E8%83%8C%E5%90%8E%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3.pdf) 一文，两个点自己看明白了

```shell
1. 微博博文存储面临巨大挑战。
    (1). 首先，我们将索引同内容进行了拆分，因为索引所需存储空间较少，而内容存储所需空间较大， 且这两者的使用需求也不尽相同，访问频次也会不同，需要区别对待。
    (2). 然后，分别对索引和内容采用先 hash，再按照时间维度拆分的方式进行水平拆分，尽量保障每张 表的容量在可控范围之内，以保证查询的性能指标。
    (3). 最后，业务先通过索引获得实际所需内容的 id，再通过内容库获得实际的内容，并通过部署 memcached 来加速整个过程，虽然看上去步骤变多，但实际效果完全可以满足业务需求。
    
    后面作者也回答了这个问题。
    (1). 针对博文时间强相关，内容数据量大的特点。把内容和索引垂直拆分成两类表，一类存储索引和博文ID，一类存储博文ID和博文内容数据；
    (2). 我们针对索引表的时间强相关特性，我们用redis做缓存，以及索引表按时间特性水平拆分，DATETIME(now-expire)则进行归档；同时博文表也进行mod%1024值(1024：表示博文拆分表的总数量)， 这1024个表也具有时间特性，整体超过某个时间，也进行归档。
    (3). 通过缓存加速索引过程。

2. 印象最深的一次数据库服务故障能否回忆并说几点注意事项?
    一同事不小心执行了drop table命令，导致线上服务受影响。所以做了一个删表需求流程， 具体如下：
    (1). 执行 rename table 操作，将 table rename 成 table—will-drop。 
    (2). 等待 24 小时之后再执行 drop 操作。
```
